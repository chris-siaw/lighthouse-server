name: Run Lighthouse and Store Results with Blob Storage

on:
  schedule:
    - cron: '0 12 * * *'  # Runs daily at 12:00 UTC
  workflow_dispatch:      # Allows manual execution

jobs:
  lighthouse:
    runs-on: ubuntu-latest

    steps:
      - name: Install Chrome
        run: |
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt install ./google-chrome-stable_current_amd64.deb

      - name: Install Lighthouse CLI
        run: npm install -g lighthouse

      - name: Install jq (JSON Parser)
        run: sudo apt-get install -y jq

      - name: Loop Through URLs from Secret
        run: |
          TARGET_URL="${{ secrets.TARGET_URL }}"
          IFS=',' read -r -a URL_ARRAY <<< "$TARGET_URL"

          for url in "${URL_ARRAY[@]}"; do
            echo "Running Lighthouse for $url"

            # Create a unique directory for each run
            REPORT_DIR="$(mktemp -d)" || { echo "Failed to create temp directory"; continue; }
            REPORT_HTML="$REPORT_DIR/report.html"
            REPORT_JSON="$REPORT_DIR/report.json"
            
            # Run Lighthouse and output results
            if ! lighthouse "$url" --output=json --output=html --quiet --chrome-flags="--no-sandbox --headless --disable-dev-shm-usage" --output-path="$REPORT_HTML" > "$REPORT_JSON"; then
              echo "Lighthouse analysis failed for $url"
              rm -rf "$REPORT_DIR"
              continue
            fi

            # Check if report files were generated
            if [ ! -f "$REPORT_HTML" ] || [ ! -f "$REPORT_JSON" ]; then
              echo "Lighthouse report files not generated for $url"
              rm -rf "$REPORT_DIR"
              continue
            fi

            # Extract performance metrics
            read PERFORMANCE ACCESSIBILITY BEST_PRACTICES SEO <<< $(jq -r '.categories | "\(.performance.score * 100) \(.accessibility.score * 100) \(.\"best-practices\".score * 100) \(.seo.score * 100)"' "$REPORT_JSON")

            # Upload HTML report to Vercel Blob Storage
            REPORT_NAME=$(date +%s)-$(echo "$url" | md5sum | cut -d' ' -f1).html
            if ! curl -f -X PUT -H "Authorization: Bearer ${{ secrets.VERCEL_BLOB_TOKEN }}" \
                 -H "Content-Type: text/html" \
                 --data-binary "@$REPORT_HTML" \
                 "https://lighthouse-storage.blob.vercel-storage.com/lighthouse-reports/$REPORT_NAME"; then
              echo "Failed to upload report to Vercel Blob Storage for $url"
              rm -rf "$REPORT_DIR"
              continue
            fi

            # Generate Public URL for the HTML Report
            REPORT_URL="https://lighthouse-storage.blob.vercel-storage.com/lighthouse-reports/$REPORT_NAME"
            echo "Generated Report URL: $REPORT_URL"

            # Store Results in Database
            url_escaped=$(echo "$url" | sed 's/['"'"']/\\&/g')
            report_url_escaped=$(echo "$REPORT_URL" | sed 's/['"'"']/\\&/g')
            if ! echo "INSERT INTO lighthouse_tests (url, performance_score, accessibility_score, best_practices_score, seo_score, report_url, timestamp)
            VALUES ('$url_escaped', $PERFORMANCE, $ACCESSIBILITY, $BEST_PRACTICES, $SEO, '$report_url_escaped', NOW());" | psql "${{ secrets.DATABASE_URL }}"; then
              echo "Failed to store results in database for $url"
              rm -rf "$REPORT_DIR"
              continue
            fi

            # Clean up temporary files
            rm -rf "$REPORT_DIR"
            echo "Cleaned up temp files for $url"
          done
