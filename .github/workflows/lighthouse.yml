name: Run Lighthouse and Store Results with Blob Storage

on:
  schedule:
    - cron: '0 12 * * *'  # Runs daily at 12:00 UTC
  workflow_dispatch:      # Allows manual execution

jobs:
  lighthouse:
    runs-on: ubuntu-latest

    steps:
      - name: Install Lighthouse and Puppeteer
        run: |
          npm install -g lighthouse puppeteer
          npm list -g lighthouse puppeteer

      - name: Install jq (JSON Parser)
        run: sudo apt-get install -y jq

      - name: Loop Through URLs from Secret
        run: |
          TARGET_URL="${{ secrets.TARGET_URL }}"
          IFS=',' read -r -a URL_ARRAY <<< "$TARGET_URL"

          for url in "${URL_ARRAY[@]}"; do
            echo "Running Lighthouse for $url"

            # Create a unique directory for each run with full permissions
            REPORT_DIR="/tmp/lighthouse-$(date +%s)"
            mkdir -p "$REPORT_DIR"
            chmod 777 "$REPORT_DIR"
            
            echo "Will save reports to: $REPORT_DIR"
            
            # Run Lighthouse with base filename
            if ! lighthouse "$url" \
              --output=json \
              --output=html \
              --quiet \
              --chrome-flags="--headless --no-sandbox --disable-dev-shm-usage" \
              --output-path="$REPORT_DIR/report" \
              --save-assets \
              --max-wait-for-load=30000 \
              --only-categories=performance,accessibility,best-practices,seo; then
              echo "Lighthouse analysis failed for $url"
              echo "Contents of report directory:"
              ls -la "$REPORT_DIR"
              rm -rf "$REPORT_DIR"
              continue
            fi

            echo "Lighthouse analysis completed. Checking for report files..."
            ls -la "$REPORT_DIR"

            # Check if report files were generated (using correct filenames)
            if [ ! -f "$REPORT_DIR/report.report.html" ] || [ ! -f "$REPORT_DIR/report.report.json" ]; then
              echo "Lighthouse report files not generated for $url"
              echo "Contents of report directory:"
              ls -la "$REPORT_DIR"
              rm -rf "$REPORT_DIR"
              continue
            fi

            echo "Report files found. Processing results..."

            # Extract performance metrics with error handling
            if ! read PERFORMANCE ACCESSIBILITY BEST_PRACTICES SEO <<< $(jq -r '.categories | "\(.performance.score * 100) \(.accessibility.score * 100) \(.\"best-practices\".score * 100) \(.seo.score * 100)"' "$REPORT_DIR/report.report.json"); then
              echo "Failed to extract metrics from JSON report"
              cat "$REPORT_DIR/report.report.json"
              rm -rf "$REPORT_DIR"
              continue
            fi

            # Upload HTML report to Vercel Blob Storage
            REPORT_NAME=$(date +%s)-$(echo "$url" | md5sum | cut -d' ' -f1).html
            echo "Uploading report to Vercel Blob Storage..."
            
            if ! curl -f -X PUT -H "Authorization: Bearer ${{ secrets.VERCEL_BLOB_TOKEN }}" \
                 -H "Content-Type: text/html" \
                 --data-binary "@$REPORT_DIR/report.report.html" \
                 "https://lighthouse-storage.blob.vercel-storage.com/lighthouse-reports/$REPORT_NAME"; then
              echo "Failed to upload report to Vercel Blob Storage for $url"
              rm -rf "$REPORT_DIR"
              continue
            fi

            # Generate Public URL for the HTML Report
            REPORT_URL="https://lighthouse-storage.blob.vercel-storage.com/lighthouse-reports/$REPORT_NAME"
            echo "Generated Report URL: $REPORT_URL"

            # Store Results in Database
            url_escaped=$(echo "$url" | sed 's/['"'"']/\\&/g')
            report_url_escaped=$(echo "$REPORT_URL" | sed 's/['"'"']/\\&/g')
            echo "Storing results in database..."
            
            if ! echo "INSERT INTO lighthouse_tests (url, performance_score, accessibility_score, best_practices_score, seo_score, report_url, timestamp)
            VALUES ('$url_escaped', $PERFORMANCE, $ACCESSIBILITY, $BEST_PRACTICES, $SEO, '$report_url_escaped', NOW());" | psql "${{ secrets.DATABASE_URL }}"; then
              echo "Failed to store results in database for $url"
              rm -rf "$REPORT_DIR"
              continue
            fi

            # Clean up temporary files
            rm -rf "$REPORT_DIR"
            echo "Successfully processed $url"
          done
